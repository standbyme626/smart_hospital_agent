import os
import sys
import json
import asyncio
import uuid
import pandas as pd
from typing import List, Dict, Any
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall,
)

# å¼ºåˆ¶ä¿®æ­£å¯¼å…¥è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, "../../../.."))
backend_dir = os.path.join(project_root, "backend")
if backend_dir not in sys.path:
    sys.path.insert(0, backend_dir)

from app.core.config import settings
from app.core.llm.llm_factory import get_judge_llm
from langchain_huggingface import HuggingFaceEmbeddings

class MedicalRAGEvaluator:
    """
    åŒ»ç–— RAG è‡ªåŠ¨åŒ–è¯„ä¼°å™¨
    åŸºäº RAGAS æ¡†æ¶ï¼Œæä¾›å¿ å®åº¦ã€ç²¾åº¦å’Œç›¸å…³æ€§çš„é‡åŒ–è¯„ä¼°
    """
    def __init__(self):
        # [V6.2 Update] ä½¿ç”¨å…·å¤‡â€œæ¨¡å‹+å¯†é’¥â€åŒé‡è‡ªæ„ˆèƒ½åŠ›çš„è£åˆ¤æ¨¡å‹
        self.judge_llm = get_judge_llm()
        
        # ä½¿ç”¨æœ¬åœ° Embedding æ¨¡å‹è¿›è¡Œè¯„ä¼°ä¸­çš„å‘é‡è®¡ç®—
        import torch
        self.embeddings = HuggingFaceEmbeddings(
            model_name=settings.EMBEDDING_MODEL_PATH,
            model_kwargs={'device': 'cpu'}
        )
        # [Fix] å¼ºåˆ¶è½¬æ¢æ¨¡å‹ä¸º float32 ä»¥é¿å… numpy ä¸æ”¯æŒ bfloat16 çš„é—®é¢˜
        if hasattr(self.embeddings, "_client"):
            self.embeddings._client.to(torch.float32)
        
        # é…ç½® RAGAS æŒ‡æ ‡
        self.metrics = [
            faithfulness,
            answer_relevancy,
            context_precision,
        ]

    async def run_evaluation(self, test_data: List[Dict[str, Any]], report_path: str = "ragas_report.csv"):
        """
        æ‰§è¡Œè¯„ä¼°æµç¨‹
        """
        print(f"[DEBUG] å¼€å§‹ RAGAS è¯„ä¼°ï¼Œæ ·æœ¬é‡: {len(test_data)}")
        
        dataset = Dataset.from_list(test_data)
        
        # æ‰§è¡Œè¯„ä¼°
        result = evaluate(
            dataset=dataset,
            metrics=self.metrics,
            llm=self.judge_llm,
            embeddings=self.embeddings, # æ˜¾å¼ä¼ å…¥ Embedding
            raise_exceptions=True       # å¼€å¯å¼‚å¸¸æŠ›å‡ºï¼Œä¾¿äºè°ƒè¯•
        )
        
        # å¯¼å‡ºæŠ¥å‘Š
        df = result.to_pandas()
        df.to_csv(report_path, index=False)
        
        # æ•…éšœæ ¹å› åˆ†æåˆ†æ
        self._generate_diagnostic_summary(df)
        
        return result

    def _generate_diagnostic_summary(self, df: pd.DataFrame):
        """
        æ ¹æ®è¯„ä¼°åˆ†æ•°è‡ªåŠ¨è¯Šæ–­ç³»ç»Ÿç“¶é¢ˆ
        """
        avg_faithfulness = df["faithfulness"].mean()
        avg_relevance = df["answer_relevancy"].mean()
        avg_precision = df["context_precision"].mean()
        
        print("\n" + "="*50)
        print("ğŸ¥ åŒ»ç–— RAG ç³»ç»Ÿè‡ªåŠ¨åŒ–è¯Šæ–­æŠ¥å‘Š")
        print("="*50)
        print(f"1. å¿ å®åº¦ (Faithfulness): {avg_faithfulness:.4f}")
        print(f"2. ç­”æ¡ˆç›¸å…³æ€§ (Relevance): {avg_relevance:.4f}")
        print(f"3. ä¸Šä¸‹æ–‡ç²¾åº¦ (Precision): {avg_precision:.4f}")
        print("-" * 50)
        
        # æ ¹å› æ˜ å°„é€»è¾‘
        if avg_faithfulness < 0.7:
            print("ğŸš© è¯Šæ–­ï¼šã€ç”Ÿæˆå±‚æ•…éšœã€‘å­˜åœ¨ä¸¥é‡å¹»è§‰é£é™©ã€‚å»ºè®®ï¼šåŠ å¼º System Prompt çº¦æŸæˆ–æ›´æ¢æ›´é«˜å‚æ•°æ¨¡å‹ã€‚")
        if avg_precision < 0.7:
            print("ğŸš© è¯Šæ–­ï¼šã€æ£€ç´¢å±‚æ•…éšœã€‘æ£€ç´¢å™ªéŸ³è¿‡å¤§ã€‚å»ºè®®ï¼šä¼˜åŒ– Reranker æ’åºæˆ–æ”¹è¿› Chunking ç­–ç•¥ã€‚")
        if avg_relevance < 0.7:
            print("ğŸš© è¯Šæ–­ï¼šã€ç†è§£å±‚æ•…éšœã€‘ç­”éæ‰€é—®ã€‚å»ºè®®ï¼šä¼˜åŒ– Query Rewriting é€»è¾‘ã€‚")
        
        if avg_faithfulness >= 0.8 and avg_precision >= 0.8:
            print("âœ… è¯Šæ–­ï¼šç³»ç»Ÿè¿è¡Œç¨³å¥ï¼Œå…·å¤‡å·¥ä¸šçº§äº¤ä»˜èƒ½åŠ›ã€‚")
        print("="*50 + "\n")

async def test_evaluator():
    # æ‰©å±•æµ‹è¯•æ•°æ®é›†ï¼Œè¦†ç›–å¤šç§åŒ»ç–—åœºæ™¯
    evaluator = MedicalRAGEvaluator()
    sample_data = [
        {
            "question": "è¡€çº¢è›‹ç™½ 90 æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ",
            "contexts": ["è¡€çº¢è›‹ç™½å‚è€ƒèŒƒå›´ä¸º 110-160g/Lã€‚90g/L å±äºè½»ä¸­åº¦è´«è¡€ã€‚"],
            "answer": "æ‚¨çš„è¡€çº¢è›‹ç™½ä¸º 90g/Lï¼Œä½äºæ­£å¸¸èŒƒå›´ï¼Œå±äºè´«è¡€ã€‚å»ºè®®å’¨è¯¢åŒ»ç”Ÿäº†è§£å…·ä½“åŸå› ã€‚",
            "ground_truth": "è¡€çº¢è›‹ç™½ 90g/L ä½äº 110-160g/L çš„æ ‡å‡†èŒƒå›´ï¼Œå±äºè´«è¡€èŒƒç•´ã€‚"
        },
        {
            "question": "å¤´ç–¼ä¼´éšå‘•ååº”è¯¥æŒ‚ä»€ä¹ˆç§‘ï¼Ÿ",
            "contexts": ["ç¥ç»å†…ç§‘ä¸»è¦è¯Šæ²»å¤´ç—›ã€å¤´æ™•ã€è‚¢ä½“éº»æœ¨ç­‰ç—‡çŠ¶ã€‚å¦‚æœä¼´æœ‰å‰§çƒˆå‘•åï¼Œéœ€è­¦æƒ•é¢…å†…å‹å¢é«˜ã€‚"],
            "answer": "å»ºè®®æ‚¨æŒ‚ç¥ç»å†…ç§‘ã€‚å¤´ç—›ä¼´éšå‘•åå¯èƒ½æ¶‰åŠç¥ç»ç³»ç»Ÿé—®é¢˜ï¼Œè¯·å°½å¿«å°±åŒ»ã€‚",
            "ground_truth": "å¤´ç—›ä¼´å‘•åå»ºè®®ä¼˜å…ˆæŒ‚ç¥ç»å†…ç§‘ï¼Œæ’é™¤é¢…å†…å‹åŠ›å¼‚å¸¸ã€‚"
        },
        {
            "question": "é˜¿å¸åŒ¹æ—è‚ æº¶ç‰‡æ€ä¹ˆåƒï¼Ÿ",
            "contexts": ["é˜¿å¸åŒ¹æ—è‚ æº¶ç‰‡åº”åœ¨é¥­å‰ç”¨é€‚é‡æ°´é€æœã€‚è‚ æº¶ç‰‡è®¾è®¡æ˜¯ä¸ºäº†åœ¨è‚ é“é‡Šæ”¾ï¼Œå‡å°‘èƒƒéƒ¨åˆºæ¿€ã€‚"],
            "answer": "é˜¿å¸åŒ¹æ—è‚ æº¶ç‰‡é€šå¸¸å»ºè®®é¥­å‰æœç”¨ï¼Œç”¨æ¸©å¼€æ°´é€æœã€‚è¯·å‹¿å‹ç¢æˆ–å’€åš¼ã€‚",
            "ground_truth": "åº”é¥­å‰é€æœï¼Œä¿æŒè¯ç‰‡å®Œæ•´ï¼Œåˆ©ç”¨å…¶è‚ æº¶ç‰¹æ€§ä¿æŠ¤èƒƒç²˜è†œã€‚"
        },
        {
            "question": "ç³–å°¿ç—…æ‚£è€…å¯ä»¥åƒè¥¿ç“œå—ï¼Ÿ",
            "contexts": ["è¥¿ç“œçš„è¡€ç³–ç”ŸæˆæŒ‡æ•°(GI)è¾ƒé«˜ï¼Œä½†å«ç³–é‡ç›¸å¯¹è¾ƒä½ã€‚ç³–å°¿ç—…æ‚£è€…åœ¨è¡€ç³–æ§åˆ¶ç¨³å®šçš„æƒ…å†µä¸‹å¯å°‘é‡é£Ÿç”¨ã€‚"],
            "answer": "ç³–å°¿ç—…æ‚£è€…åœ¨è¡€ç³–å¹³ç¨³æ—¶å¯ä»¥å°‘é‡åƒè¥¿ç“œï¼ˆå»ºè®®ä¸è¶…è¿‡ 200gï¼‰ï¼Œä½†è¦æ³¨æ„ç›‘æµ‹è¡€ç³–æ³¢åŠ¨ã€‚",
            "ground_truth": "è¡€ç³–ç¨³å®šæ—¶å¯é™é‡é£Ÿç”¨ï¼Œè¥¿ç“œ GI å€¼é«˜ä½†å«ç³–é‡ä½ï¼Œå…³é”®åœ¨äºæ§åˆ¶æ€»é‡ã€‚"
        },
        {
            "question": "è¿‡æ•æ€§é¼»ç‚æœ‰å“ªäº›ç—‡çŠ¶ï¼Ÿ",
            "contexts": ["è¿‡æ•æ€§é¼»ç‚å…¸å‹ç—‡çŠ¶åŒ…æ‹¬é˜µå‘æ€§å–·åšã€æ¸…æ°´æ ·é¼»æ¶•ã€é¼»ç—’å’Œé¼»å¡ã€‚å¸¸ä¼´æœ‰çœ¼ç—’ã€ç»“è†œå……è¡€ã€‚"],
            "answer": "è¿‡æ•æ€§é¼»ç‚å¸¸è¡¨ç°ä¸ºæ‰“å–·åšã€æµæ¸…é¼»æ¶•ã€é¼»å­ç—’å’Œé¼»å¡ã€‚éƒ¨åˆ†æ‚£è€…è¿˜ä¼šçœ¼ç›çº¢ç—’ã€‚",
            "ground_truth": "ä¸»è¦ç—‡çŠ¶ä¸ºå–·åšã€æ¸…æ¶•ã€é¼»ç—’é¼»å¡ï¼Œå¯èƒ½ä¼´æœ‰çœ¼éƒ¨è¿‡æ•ç—‡çŠ¶ã€‚"
        }
    ]
    await evaluator.run_evaluation(sample_data)

if __name__ == "__main__":
    import sys
    # ä¿®å¤å¯¼å…¥è·¯å¾„ä»¥ä¾¿ç›´æ¥è¿è¡Œ
    sys.path.append(os.path.join(os.getcwd(), "backend"))
    asyncio.run(test_evaluator())
