import os
import sys
import asyncio
import pandas as pd
from typing import List, Dict, Any
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
)

# è·¯å¾„ä¿®æ­£
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, "../../../.."))
backend_dir = os.path.join(project_root, "backend")
if backend_dir not in sys.path:
    sys.path.insert(0, backend_dir)

from app.core.config import settings
from app.core.llm.llm_factory import SmartRotatingLLM
from langchain_huggingface import HuggingFaceEmbeddings
import torch

class ComparisonEvaluator:
    def __init__(self):
        # åˆå§‹åŒ–ä¸¤ç§è£åˆ¤ï¼šæœ¬åœ°ä¼˜å…ˆ vs äº‘ç«¯ä¼˜å…ˆ
        self.local_judge = SmartRotatingLLM(temperature=0.0, max_tokens=512, prefer_local=True)
        self.cloud_judge = SmartRotatingLLM(temperature=0.0, max_tokens=512, prefer_local=False)
        
        # å…¬ç”¨çš„ Embedding
        self.embeddings = HuggingFaceEmbeddings(
            model_name=settings.EMBEDDING_MODEL_PATH,
            model_kwargs={'device': 'cpu'}
        )
        if hasattr(self.embeddings, "_client"):
            self.embeddings._client.to(torch.float32)
            
        self.metrics = [faithfulness, answer_relevancy, context_precision]

    async def run_comparison(self, test_data: List[Dict[str, Any]]):
        dataset = Dataset.from_list(test_data)
        
        print("\nğŸš€ [1/2] æ­£åœ¨è¿è¡Œã€æœ¬åœ°æ¨¡å‹ Qwen3-1.7Bã€‘æ‰“åˆ†...")
        local_result = evaluate(
            dataset=dataset,
            metrics=self.metrics,
            llm=self.local_judge,
            embeddings=self.embeddings,
            raise_exceptions=True
        )
        local_df = local_result.to_pandas()
        
        print("\nğŸš€ [2/2] æ­£åœ¨è¿è¡Œã€äº‘ç«¯å¤§æ¨¡å‹ Qwen-Turbo/Plusã€‘æ‰“åˆ†...")
        cloud_result = evaluate(
            dataset=dataset,
            metrics=self.metrics,
            llm=self.cloud_judge,
            embeddings=self.embeddings,
            raise_exceptions=True
        )
        cloud_df = cloud_result.to_pandas()
        
        # åˆå¹¶å¯¹æ¯”ç»“æœ
        comparison_report = []
        for i in range(len(test_data)):
            comparison_report.append({
                "Question": test_data[i]["question"],
                "Local_Faithfulness": local_df.iloc[i]["faithfulness"],
                "Cloud_Faithfulness": cloud_df.iloc[i]["faithfulness"],
                "Local_Relevancy": local_df.iloc[i]["answer_relevancy"],
                "Cloud_Relevancy": cloud_df.iloc[i]["answer_relevancy"],
                "Local_Precision": local_df.iloc[i]["context_precision"],
                "Cloud_Precision": cloud_df.iloc[i]["context_precision"],
            })
            
        report_df = pd.DataFrame(comparison_report)
        report_df.to_csv("evaluator_comparison_20.csv", index=False)
        
        # æ‰“å°æ±‡æ€»å¯¹æ¯”
        print("\n" + "="*60)
        print("ğŸ“Š æœ¬åœ° vs äº‘ç«¯è£åˆ¤è¯„åˆ†æ¨ªå‘å¯¹æ¯”æ±‡æ€»")
        print("="*60)
        print(f"{'æŒ‡æ ‡':<20} | {'æœ¬åœ°å¹³å‡åˆ†':<12} | {'äº‘ç«¯å¹³å‡åˆ†':<12} | {'å·®å¼‚':<8}")
        print("-" * 60)
        
        metrics_names = ["faithfulness", "answer_relevancy", "context_precision"]
        for m in metrics_names:
            l_avg = local_df[m].mean()
            c_avg = cloud_df[m].mean()
            diff = l_avg - c_avg
            print(f"{m:<20} | {l_avg:<12.4f} | {c_avg:<12.4f} | {diff:<8.4f}")
        print("="*60)
        print("è¯¦ç»†å¯¹æ¯”å·²ä¿å­˜è‡³: evaluator_comparison_20.csv\n")

async def main():
    # æ„é€  20 ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„åŒ»ç–— RAG æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {"question": "é«˜è¡€å‹æ‚£è€…èƒ½ä¸èƒ½åƒå’¸èœï¼Ÿ", "contexts": ["é«˜è¡€å‹æ‚£è€…éœ€é™åˆ¶é’ ç›æ‘„å…¥ï¼Œå»ºè®®æ¯æ—¥é£Ÿç›é‡ä¸è¶…è¿‡5gã€‚å’¸èœå«æœ‰æé«˜çš„é’ ç›ã€‚"], "answer": "ä¸å¯ä»¥åƒï¼Œå’¸èœç›åˆ†å¤ªé«˜ä¼šå‡é«˜è¡€å‹ã€‚", "ground_truth": "ä¸èƒ½åƒã€‚å’¸èœå«é’ ç›è¿‡é«˜ï¼Œé«˜è¡€å‹æ‚£è€…åº”é™ç›ã€‚"},
        {"question": "å¸ƒæ´›èŠ¬å’Œå¯¹ä¹™é…°æ°¨åŸºé…šèƒ½ä¸€èµ·åƒå—ï¼Ÿ", "contexts": ["å¸ƒæ´›èŠ¬å’Œå¯¹ä¹™é…°æ°¨åŸºé…šåŒå±è§£çƒ­é•‡ç—›è¯ï¼Œåˆç”¨ä¼šå¢åŠ è‚¾æ¯’æ€§å’Œèƒƒè‚ é“é£é™©ã€‚"], "answer": "å¯ä»¥ä¸€èµ·åƒï¼Œæ•ˆæœæ›´å¥½ã€‚", "ground_truth": "ä¸èƒ½ã€‚åˆç”¨ä¼šå¢åŠ å‰¯ä½œç”¨é£é™©ã€‚"},
        {"question": "æ„Ÿå†’äº†æµé»„é¼»æ¶•æ˜¯ç—…æ¯’è¿˜æ˜¯ç»†èŒï¼Ÿ", "contexts": ["ç—…æ¯’æ„ŸæŸ“åˆæœŸå¤šä¸ºæ¸…æ¶•ï¼Œç»§å‘ç»†èŒæ„ŸæŸ“æˆ–ç‚ç—‡åæœŸå¯èƒ½å‡ºç°é»„è„“æ¶•ã€‚"], "answer": "æµé»„é¼»æ¶•é€šå¸¸æç¤ºå¯èƒ½å­˜åœ¨ç»†èŒæ„ŸæŸ“ã€‚", "ground_truth": "å¯èƒ½æç¤ºç»§å‘ç»†èŒæ„ŸæŸ“ï¼Œä½†ä¹Ÿå¯èƒ½æ˜¯ç—…æ¯’æ„ŸæŸ“åæœŸè¡¨ç°ã€‚"},
        {"question": "å¤‡å­•æœŸé—´èƒ½ä¸èƒ½ç…§ X å…‰ï¼Ÿ", "contexts": ["Xå°„çº¿å…·æœ‰ç”µç¦»è¾å°„ï¼Œå¯èƒ½å½±å“ç”Ÿæ®–ç»†èƒã€‚å»ºè®®ç…§Xå…‰å3ä¸ªæœˆå†æ€€å­•ã€‚"], "answer": "å¯ä»¥ç…§ï¼Œæ²¡å½±å“ã€‚", "ground_truth": "ä¸å»ºè®®ã€‚Xå°„çº¿è¾å°„å¯èƒ½å½±å“èƒšèƒï¼Œå»ºè®®é—´éš”3ä¸ªæœˆã€‚"},
        {"question": "å­©å­å‘çƒ§ 38.5 åº¦æ€ä¹ˆåŠï¼Ÿ", "contexts": ["å°å„¿å‘çƒ­è¶…è¿‡38.5â„ƒå»ºè®®ä½¿ç”¨é€€çƒ§è¯ï¼ˆå¦‚ç¾æ—ï¼‰ï¼Œå¹¶é…åˆç‰©ç†é™æ¸©ã€‚"], "answer": "ç»™å­©å­åƒé€€çƒ§è¯ï¼Œå¹¶å¤šå–æ°´ã€‚è¶…è¿‡38.5åº¦éœ€è¦è¯ç‰©å¹²é¢„ã€‚", "ground_truth": "å»ºè®®æœç”¨é€€çƒ§è¯å¹¶ç‰©ç†é™æ¸©ã€‚"},
        {"question": "ä½“æ£€å‘ç°èƒ†å›Šæ¯è‚‰ 0.5cm ä¸¥é‡å—ï¼Ÿ", "contexts": ["å°äº1cmçš„èƒ†å›Šæ¯è‚‰å¤šä¸ºè‰¯æ€§ï¼Œå»ºè®®æ¯åŠå¹´å¤æŸ¥å½©è¶…ã€‚è‹¥å¤§äº1cmæˆ–å¢é•¿å¿«éœ€æ‰‹æœ¯ã€‚"], "answer": "0.5cm æ¯”è¾ƒå°ï¼Œé€šå¸¸ä¸ä¸¥é‡ï¼Œå®šæœŸå¤æŸ¥å³å¯ã€‚", "ground_truth": "é€šå¸¸ä¸ä¸¥é‡ï¼Œå»ºè®®å®šæœŸéšè®¿è§‚å¯Ÿã€‚"},
        {"question": "æŠ—ç”Ÿç´ åƒä¸‰å¤©æ„Ÿè§‰å¥½äº†èƒ½åœå—ï¼Ÿ", "contexts": ["æŠ—ç”Ÿç´ éœ€è¶³ç–—ç¨‹ä½¿ç”¨ï¼Œæ“…è‡ªåœè¯æ˜“å¯¼è‡´ç»†èŒè€è¯å’Œç—…æƒ…åå¤ã€‚"], "answer": "æ„Ÿè§‰å¥½äº†å°±å¯ä»¥åœï¼Œå°‘åƒè¯å¯¹èº«ä½“å¥½ã€‚", "ground_truth": "ä¸èƒ½åœã€‚å¿…é¡»éµåŒ»å˜±å®Œæˆæ•´ä¸ªç–—ç¨‹ã€‚"},
        {"question": "è„‚è‚ªè‚æ€ä¹ˆè°ƒç†ï¼Ÿ", "contexts": ["è„‚è‚ªè‚è°ƒç†æ ¸å¿ƒæ˜¯â€œç®¡ä½å˜´ã€è¿ˆå¼€è…¿â€ï¼Œç¦é…’ã€å‡é‡ã€ä½è„‚é¥®é£Ÿã€‚"], "answer": "å¤šè¿åŠ¨ï¼Œå°‘åƒæ²¹è…»ï¼Œæˆ’é…’ï¼Œæ§åˆ¶ä½“é‡ã€‚", "ground_truth": "é€šè¿‡æ§åˆ¶é¥®é£Ÿã€åŠ å¼ºè¿åŠ¨å’Œå‡é‡æ¥æ”¹å–„ã€‚"},
        {"question": "è…°é—´ç›˜çªå‡ºèƒ½ç¡è½¯åºŠå—ï¼Ÿ", "contexts": ["è…°æ¤é—´ç›˜çªå‡ºæ‚£è€…å»ºè®®ç¡ç¡¬æ¿åºŠï¼Œä»¥ç»´æŒè…°æ¤ç”Ÿç†æ›²åº¦ã€‚"], "answer": "è½¯åºŠèˆ’æœï¼Œå¯ä»¥ç¡è½¯åºŠã€‚", "ground_truth": "ä¸å»ºè®®ã€‚åº”ç¡ç¡¬æ¿åºŠä»¥ä¿æŠ¤è…°æ¤ã€‚"},
        {"question": "è´«è¡€åƒä»€ä¹ˆè¡¥å¾—å¿«ï¼Ÿ", "contexts": ["ç¼ºé“æ€§è´«è¡€å»ºè®®é£Ÿç”¨åŠ¨ç‰©è‚è„ã€è¡€è±†è…ã€ç˜¦è‚‰ç­‰å¯Œå«è¡€çº¢ç´ é“çš„é£Ÿç‰©ã€‚"], "answer": "å¤šåƒçº¢æ£å’Œèµ¤è±†ï¼Œè¿™äº›è¡¥è¡€æœ€å¿«ã€‚", "ground_truth": "åº”å¤šåƒåŠ¨ç‰©æ€§é£Ÿå“å¦‚è‚è„ã€è¡€åˆ¶å“ã€‚"},
        {"question": "è¿‡æ•æ€§å“®å–˜èƒ½æ²»æ„ˆå—ï¼Ÿ", "contexts": ["å“®å–˜ç›®å‰æ— æ³•æ ¹æ²»ï¼Œä½†é€šè¿‡è§„èŒƒåŒ–æ²»ç–—å¯ä»¥å®ç°é•¿æœŸä¸´åºŠæ§åˆ¶ã€‚"], "answer": "å¯ä»¥å®Œå…¨æ²»æ„ˆï¼Œå†ä¹Ÿä¸å¤å‘ã€‚", "ground_truth": "æ— æ³•æ ¹æ²»ï¼Œä½†å¯ä»¥è¾¾åˆ°ä¸´åºŠæ§åˆ¶ã€‚"},
        {"question": "å°¿é…¸é«˜å°±æ˜¯ç—›é£å—ï¼Ÿ", "contexts": ["é«˜å°¿é…¸è¡€ç—‡æ˜¯ç—›é£çš„ç—…ç†åŸºç¡€ï¼Œä½†ä»…æœ‰çº¦10%-20%çš„é«˜å°¿é…¸æ‚£è€…ä¼šå‘å±•ä¸ºç—›é£ã€‚"], "answer": "å°¿é…¸é«˜å°±ä»£è¡¨ä½ å·²ç»å¾—ç—›é£äº†ã€‚", "ground_truth": "ä¸ä¸€å®šã€‚é«˜å°¿é…¸æ˜¯ç—›é£çš„å‰å…†ï¼Œä½†ä¸ç­‰åŒäºç—›é£ã€‚"},
        {"question": "èƒƒæºƒç–¡èƒ½ä¸èƒ½å–å’–å•¡ï¼Ÿ", "contexts": ["å’–å•¡å› ä¼šåˆºæ¿€èƒƒé…¸åˆ†æ³Œï¼ŒåŠ é‡èƒƒæºƒç–¡ç—‡çŠ¶ï¼Œå»ºè®®æ€¥æ€§æœŸç¦é¥®ã€‚"], "answer": "å°‘å–ä¸€ç‚¹æ²¡å…³ç³»ã€‚", "ground_truth": "ä¸å»ºè®®å–ã€‚ä¼šåˆºæ¿€èƒƒé…¸åˆ†æ³ŒåŠ é‡ç—…æƒ…ã€‚"},
        {"question": "ä¸­æš‘äº†å–è—¿é¦™æ­£æ°”æ°´æœ‰ç”¨å—ï¼Ÿ", "contexts": ["è—¿é¦™æ­£æ°”æ°´å«æœ‰ä¹™é†‡ï¼Œä¸é€‚ç”¨äºè„±æ°´å‹ä¸­æš‘ã€‚ä¸»è¦ç”¨äºæš‘æ¹¿æ„Ÿå†’ã€‚"], "answer": "éå¸¸æœ‰æ•ˆæœï¼Œæ˜¯ä¸­æš‘é¦–é€‰è¯ã€‚", "ground_truth": "éœ€å¯¹ç—‡ã€‚å¯¹äºé…’ç²¾æ•æ„Ÿæˆ–è„±æ°´æ€§ä¸­æš‘ä¸å®œä½¿ç”¨ã€‚"},
        {"question": "è¿‘è§†æ‰‹æœ¯åä¼šåå¼¹å—ï¼Ÿ", "contexts": ["è¿‘è§†æ‰‹æœ¯æ˜¯åˆ‡å‰Šè§’è†œï¼Œæœ¬èº«ä¸åå¼¹ï¼Œä½†è‹¥ä¸æ³¨æ„ç”¨çœ¼ä¹ æƒ¯å¯èƒ½äº§ç”Ÿæ–°è¿‘è§†ã€‚"], "answer": "æ‰‹æœ¯åšå®Œå°±ä¸€åŠ³æ°¸é€¸ï¼Œç»å¯¹ä¸åå¼¹ã€‚", "ground_truth": "æ‰‹æœ¯æœ¬èº«ä¸åå¼¹ï¼Œä½†éœ€æ³¨æ„ç”¨çœ¼å«ç”Ÿé˜²æ­¢æ–°è¿‘è§†ã€‚"},
        {"question": "å¿ƒè„æ—©æä¸€å®šè¦åƒè¯å—ï¼Ÿ", "contexts": ["å¶å‘æ—©æä¸”æ— ç—‡çŠ¶è€…é€šå¸¸æ— éœ€æ²»ç–—ï¼›é¢‘å‘æˆ–æœ‰æ˜æ˜¾ç—‡çŠ¶è€…éœ€ç”¨è¯ã€‚"], "answer": "æ—©æå¿…é¡»åƒè¯ï¼Œå¦åˆ™æœ‰ç”Ÿå‘½å±é™©ã€‚", "ground_truth": "è§†æƒ…å†µè€Œå®šã€‚æ— ç—‡çŠ¶å¶å‘è€…å¸¸ä¸éœ€æœè¯ã€‚"},
        {"question": "ç”²å‡éœ€è¦ç»ˆèº«æœè¯å—ï¼Ÿ", "contexts": ["å¤§å¤šæ•°åŸå‘æ€§ç”²å‡æ‚£è€…éœ€è¦ç»ˆèº«æœç”¨å·¦ç”²çŠ¶è…ºç´ é’ æ›¿ä»£æ²»ç–—ã€‚"], "answer": "çœ‹å¿ƒæƒ…ï¼ŒæŒ‡æ ‡å¥½äº†å°±èƒ½åœã€‚", "ground_truth": "å¤§å¤šæ•°æƒ…å†µä¸‹éœ€è¦ç»ˆèº«æ›¿ä»£æ²»ç–—ã€‚"},
        {"question": "å¸¦çŠ¶ç–±ç–¹ä¼šä¼ æŸ“å—ï¼Ÿ", "contexts": ["å¸¦çŠ¶ç–±ç–¹æœ¬èº«ä¸ä¼ æŸ“ï¼Œä½†æ°´ç–±æ¶²å«ç—…æ¯’ï¼Œå¯èƒ½å¯¼è‡´æœªæ‚£è¿‡æ°´ç—˜çš„äººæ„ŸæŸ“æ°´ç—˜ã€‚"], "answer": "ä¸ä¼šä¼ æŸ“ï¼Œæ”¾å¿ƒå§ã€‚", "ground_truth": "ä¸ç›´æ¥ä¼ æŸ“å¸¦çŠ¶ç–±ç–¹ï¼Œä½†å¯èƒ½ä¼ æ’­æ°´ç—˜ç—…æ¯’ã€‚"},
        {"question": "é•¿æœŸåƒé™å‹è¯ä¼¤è‚¾å—ï¼Ÿ", "contexts": ["é«˜è¡€å‹æœ¬èº«æ‰ä¼¤è‚¾ã€‚è§„èŒƒä½¿ç”¨é™å‹è¯åè€Œèƒ½ä¿æŠ¤è‚¾è„ï¼Œå‡å°‘å¹¶å‘ç—‡ã€‚"], "answer": "æ˜¯è¯ä¸‰åˆ†æ¯’ï¼Œé™å‹è¯è‚¯å®šä¼¤è‚¾ã€‚", "ground_truth": "ä¸ã€‚è§„èŒƒé™å‹èƒ½ä¿æŠ¤è‚¾åŠŸèƒ½ï¼Œé«˜è¡€å‹æœ¬èº«æ›´ä¼¤è‚¾ã€‚"},
        {"question": "æŠ½çƒŸå¯¹ä¼¤å£æ„ˆåˆæœ‰å½±å“å—ï¼Ÿ", "contexts": ["é¦™çƒŸä¸­çš„å°¼å¤ä¸ä¼šå¯¼è‡´è¡€ç®¡æ”¶ç¼©ï¼Œå‡å°‘ç»„ç»‡è¡€ä¾›ï¼Œå»¶ç¼“ä¼¤å£æ„ˆåˆã€‚"], "answer": "æ²¡å½±å“ï¼Œå°‘æŠ½ä¸¤æ ¹å°±è¡Œã€‚", "ground_truth": "æœ‰å½±å“ã€‚ä¼šå»¶ç¼“æ„ˆåˆé€Ÿåº¦ï¼Œå¢åŠ æ„ŸæŸ“é£é™©ã€‚"}
    ]
    
    evaluator = ComparisonEvaluator()
    await evaluator.run_comparison(test_cases)

if __name__ == "__main__":
    asyncio.run(main())
